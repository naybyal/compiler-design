C O M P I L E R
  -> program that can read a program in one language (source) and translate it into
     equivalent program in another language (target)
  -> { IMPORTANT ROLE } : report any errors in source program that it detects
                          during translation
  -> Classified as      (depending on functionality)
      -> single pass
      -> multi-pass
      -> load-and-go
      -> debugging
      -> optimizing

A N A L Y S I S       P H A S E 
  (of the source program)

  -> 3 phases
    
    -> LEXICAL ANALYSIS
      - { scanning }
      - reads the characters in the source program and groups them into tokens
        (tokens => logically cohesive sequence of characters)
      - blanks/spaces separating the tokens are normally eliminated during lexical analysis
      - { ISSUES } :
          - simplicity of design
          - efficiency 
          - portability

    -> SYNTAX ANALYSIS
      - { hierarchial analysis | parsing }
      - groups the tokens of the source program into GRAMMATICAL PHRASES that are
        used by the compiler to synthesise output.
      - represented using SYNTAX TREE (AST => ABSTRACT SYNTAX TREE)
      - interior nodes => operators; exterior nodes => operands


    -> SEMANTIC ANALYSIS
      - checks the src program for semantic errors and gathers type info. for subsequent
        code generation phase 
      - { IMPORTANT COMPONENT } : type checking
      - here, compiler checks that each operator has operands that are permitted by the source language 
        specification


S Y N T H E S I S     P H A S E
  (of the source program)

  -> 3 phases

    -> INTERMEDIATE CODE GENERATION
      - explicit low-level or machine-like intermediate representation (prgm. for an abstract machine)
      - { IMPORTANT PROPERTIES }
          : Simple and easy to produce
          : Easy to translate into the target machine
      - can be represented as AST, POSTFIX NOTATION, THREE-ADDRESS CODE, CONTROL FLOW GRAPH, DIRECTED ACYCLIC GRAPH, 
        REGISTER TRANSFER LANGUAGE


    -> CODE OPTIMIZATION
      - improves the intermediate code to produce better target code
      - it can be machine-dependent and machine-independent
      - { OBJECTIVES }
          : faster execution
          : shorter code
          : lesser power consuming target code


    -> CODE GENERATION
      - input : intermediate representation of the source program
      - intermediate code is translated to target language
      - { CRUCIAL ASPECT } : judicious assignment of registers to hold variables
      - if the target language is assembly language, this phase generate the assembly code as output



Symbol Table
  - data structure containing a record for each variable name, with fields for the attributes of the name

Token 
  - sequence of character that can be treated as a single logical entity.
  - 5 tokens are { IDENTIFIERS, KEYWORDS, OPERATORS, SPECIAL SYMBOLS, CONSTANTS }

Pattern
  - set of strings in the input for which the same token is produced as output. 
  - this set of strings is described by a rule called a pattern associated with the token

Lexeme
  - sequence of characters in the source program that is matched by a pattern for a token



C O M P I L E R   W R I T I N G   T O O L S 

A) PARSER GENERATORS
  -> input : grammatical description of a programming language (generally Context Free Grammar)
  -> output : syntax analysers
  -> easiest to implement

B) SCANNER GENERATORS
  -> input : regular expression description of the tokens of a language
  -> output : lexical analyzers
  -> lexical analyzers are generated, normally from a specification based on regular expressions
  -> basic organization of the resulting lexical analyzer is in effect a finite automaton

C) SYNTAX-DIRECTED TRANSLATION ENGINES
  -> input : parse tree 
  -> output : intermediate code
  -> these produce collections of routines that walk the parse tree, generating intermediate code.
  -> the basic idea is that one or more 'translations' are associated with each node of the parse tree, and 
      each translation is defined in terms of translations at its neigbour nodes in the tree.

D) AUTOMATIC CODE GENERATORS
  -> input : intermediate language
  -> output : machine language
  -> such a tool takes a collection of rules that define the translation of each operation of the intermediate
      language into machine language for the target machine
  -> the rules must include sufficient detail that we can handle the different possible access methods for data.

E) DATA-FLOW ANALYSIS ENGINES
  -> gathers information i.e., the values transmitted from one part of a program to each other parts.
  -> data-flow analysis is a key part of code optimization.



ERROR RECOVERY STRATEGIES IN LEXICAL ANALYSIS
  -> panic mode recovery 
      - delete successive characters from the remaining input, until the lexer can find a well-formed token at the beginning of what input is left

  -> delete one character from the remaining input

  -> insert a missing character into the remaining input

  -> replace a character by another character

  -> transpose two adjacent characters


